{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from openai_services import ai_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_kay = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "def avaliar_componentes_com_bertscore(texto_gerado, componentes_esperados, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Verifica se os componentes esperados est√£o presentes no texto gerado,\n",
    "    com base na similaridade sem√¢ntica (BERTScore F1).\n",
    "\n",
    "    Args:\n",
    "        texto_gerado (str): Texto gerado pelo modelo LLM.\n",
    "        componentes_esperados (List[str]): Lista dos nomes dos componentes que devem ser identificados.\n",
    "        threshold (float): Valor m√≠nimo do F1-score para considerar um componente detectado (default: 0.6)\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: Lista de componentes detectados com seus respectivos F1 scores.\n",
    "    \"\"\"\n",
    "    detectados = []\n",
    "\n",
    "    for componente in componentes_esperados:\n",
    "        # Frase de refer√™ncia artificial para gerar contexto\n",
    "        referencia = [f\"This mentions {componente}\"]\n",
    "        candidato = [texto_gerado]\n",
    "\n",
    "        _, _, F1 = score(candidato, referencia, lang=\"en\", verbose=False)\n",
    "\n",
    "        if F1[0].item() >= threshold:\n",
    "            detectados.append((componente, round(F1[0].item(), 3)))\n",
    "\n",
    "    return detectados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ai_flow.Chat(openai_api_key=openai_api_kay, model=\"o4-mini-2025-04-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "def extrair_componentes_de_imagem(img_path):\n",
    "    \"\"\"\n",
    "    Recebe a imagem e o handler de leitura (ex: chat.read_architecture),\n",
    "    retorna a lista de componentes identificados.\n",
    "\n",
    "    Args:\n",
    "        arquitetura: imagem ou caminho da imagem da arquitetura\n",
    "        chat_handler: fun√ß√£o que processa a imagem e retorna JSON (ex: chat.read_architecture)\n",
    "\n",
    "    Returns:\n",
    "        List[str]: lista de componentes identificados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(img_path, \"rb\") as img_file:\n",
    "            response = chat.read_architecture(img_file)\n",
    "\n",
    "        # Limpeza b√°sica da resposta textuals\n",
    "        response = response.replace('```', '').replace('json', '').strip()\n",
    "\n",
    "        resultado = json.loads(response)\n",
    "\n",
    "        return resultado.get(\"componentes_identificados\", [])\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Erro ao decodificar JSON: {str(e)}\\nResposta: {response}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def pipeline_avaliacao(\n",
    "    pasta_imagens,\n",
    "    listas_esperadas,\n",
    "    threshold=0.6,\n",
    "    extensao=\".png\"\n",
    "):\n",
    "    resultados = []\n",
    "\n",
    "    arquivos = sorted([f for f in os.listdir(pasta_imagens) if f.endswith(extensao)])\n",
    "\n",
    "    for idx, nome_arquivo in enumerate(arquivos):\n",
    "        caminho_imagem = os.path.join(pasta_imagens, nome_arquivo)\n",
    "        lista_esperada = listas_esperadas[idx]\n",
    "\n",
    "        print(f\"üîç Processando {nome_arquivo}...\")\n",
    "\n",
    "        # Extrai componentes detectados\n",
    "        detectados = extrair_componentes_de_imagem(caminho_imagem)\n",
    "\n",
    "        # Junta os componentes detectados em string para BERTScore\n",
    "        texto_gerado = \", \".join(detectados)\n",
    "\n",
    "        # Avalia com BERTScore\n",
    "        avaliados = avaliar_componentes_com_bertscore(texto_gerado, lista_esperada, threshold=threshold)\n",
    "\n",
    "        # Extrai s√≥ os nomes dos que foram considerados corretos\n",
    "        corretos = [comp for comp, _ in avaliados]\n",
    "\n",
    "        # F1 m√©dio dos componentes corretos\n",
    "        f1_medio = round(sum(f1 for _, f1 in avaliados) / len(avaliados), 3) if avaliados else 0.0\n",
    "\n",
    "        resultados.append({\n",
    "            \"imagem\": nome_arquivo,\n",
    "            \"componentes_esperados\": lista_esperada,\n",
    "            \"componentes_detectados\": detectados,\n",
    "            \"componentes_corretos\": corretos,\n",
    "            \"f1_medio\": f1_medio\n",
    "        })\n",
    "\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Enviando mensagem para an√°lise de arquitetura.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processando aws_1.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:An√°lise de arquitetura conclu√≠da.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Enviando mensagem para an√°lise de arquitetura.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processando aws_2.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:An√°lise de arquitetura conclu√≠da.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Enviando mensagem para an√°lise de arquitetura.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processando aws_3.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:An√°lise de arquitetura conclu√≠da.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Enviando mensagem para an√°lise de arquitetura.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processando azure_1.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:An√°lise de arquitetura conclu√≠da.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Enviando mensagem para an√°lise de arquitetura.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processando azure_2.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:An√°lise de arquitetura conclu√≠da.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Enviando mensagem para an√°lise de arquitetura.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processando azure_3.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:An√°lise de arquitetura conclu√≠da.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        imagem                              componentes_esperados  \\\n",
      "0    aws_1.png  [Usuarios, AWS WAF, AWS CloudFront, AWS S3, AW...   \n",
      "1    aws_2.png  [Clinical documents, Direct Connect, Amazon S3...   \n",
      "2    aws_3.png  [Migration automation Server, Amazon Cloudfron...   \n",
      "3  azure_1.png  [Users, Client Devices , Azure Function, Azure...   \n",
      "4  azure_2.png  [HTTP Traffic, Ingestion Service, Azure servic...   \n",
      "5  azure_3.png  [Customer, Browser, Azure CDN, Blob Storage, V...   \n",
      "\n",
      "                              componentes_detectados  \\\n",
      "0  [AWS - WAF, AWS - CloudFront, AWS - API Gatewa...   \n",
      "1  [On-Premises - Clinical Documents, AWS - Direc...   \n",
      "2  [On-Premises Migration Automation Server, Amaz...   \n",
      "3  [Azure Function (Collect device telemetry), Az...   \n",
      "4  [HTTP Ingress (entrada de tr√°fego HTTP), Azure...   \n",
      "5  [Azure Blob Storage, Azure CDN, Azure Applicat...   \n",
      "\n",
      "                                componentes_corretos  f1_medio  \n",
      "0  [Usuarios, AWS WAF, AWS CloudFront, AWS S3, AW...     0.811  \n",
      "1  [Clinical documents, Direct Connect, Amazon S3...     0.806  \n",
      "2  [Migration automation Server, Amazon Cloudfron...     0.813  \n",
      "3  [Users, Client Devices , Azure Function, Azure...     0.830  \n",
      "4  [HTTP Traffic, Ingestion Service, Azure servic...     0.812  \n",
      "5  [Customer, Browser, Azure CDN, Blob Storage, V...     0.800  \n"
     ]
    }
   ],
   "source": [
    "# Caminho da pasta com imagens\n",
    "pasta = \"bert-dataset/\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Listas esperadas, na mesma ordem dos arquivos na pasta\n",
    "listas_esperadas = [\n",
    "    ['Usuarios', 'AWS WAF', 'AWS CloudFront', 'AWS S3', 'AWS API Gateway', 'AWS lambda', 'AWS SES', 'AWS Dynamo DB'],\n",
    "    ['Clinical documents', 'Direct Connect', 'Amazon S3', 'Amazon Textract', 'Amazon OpenSearch', 'AWS Lambda', 'Amazon EC2', 'Amazon EKS', 'Amazon MQ', 'Amazon Sagemaker', 'Amazon Bedrock', 'Amazon RDS'],\n",
    "    ['Migration automation Server', 'Amazon Cloudfront', 'Amazon API Gateway', 'AWS Secrets Manager', 'AWS S3', 'AWS Lambda', 'AWS Systems Manager', 'Amazon Cognito', 'Amazon CloudEndure', 'Amazon Dynamo DB', 'Amazon EC2', 'Amazon MGN', 'Amazon Quicksight'],\n",
    "    ['Users', 'Client Devices ', 'Azure Function', 'Azure Events Hubs', 'Azure Event Grid', 'Azure Blob Storage', 'Applications/Service', 'Azure data Explorer', 'Metrics Advisor', 'Grafana'],\n",
    "    ['HTTP Traffic', 'Ingestion Service', 'Azure service Bus', 'Managed Identities', 'Azure key vault', 'Azure application Insights', 'Azure Monitor', 'Azure log analytics', 'Workflow service', 'Package service', 'Container app', 'Azure CosmosDB', 'Azure Cosmos for MongoDB API', 'Azure Cache for Redis'],\n",
    "    ['Customer', 'Browser', 'Azure CDN', 'Blob Storage', 'Virtual Network', 'Web App Content', 'Redis Cache', 'SQL Database', 'API App', 'Application Gateway', 'Azure active Directory', 'Application Insights', 'Emproyee']\n",
    "]\n",
    "\n",
    "# Rodar o pipeline\n",
    "resultado_final = pipeline_avaliacao(pasta, listas_esperadas)\n",
    "\n",
    "# Transformar em DataFrame\n",
    "df_resultados = pd.DataFrame(resultado_final)\n",
    "\n",
    "# Ver no console\n",
    "print(df_resultados)\n",
    "\n",
    "# Opcional: salvar em CSV\n",
    "df_resultados.to_csv(\"avaliacao_arquiteturas.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagem</th>\n",
       "      <th>componentes_esperados</th>\n",
       "      <th>componentes_detectados</th>\n",
       "      <th>componentes_corretos</th>\n",
       "      <th>f1_medio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aws_1.png</td>\n",
       "      <td>[Usuarios, AWS WAF, AWS CloudFront, AWS S3, AW...</td>\n",
       "      <td>[AWS - WAF, AWS - CloudFront, AWS - API Gatewa...</td>\n",
       "      <td>[Usuarios, AWS WAF, AWS CloudFront, AWS S3, AW...</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws_2.png</td>\n",
       "      <td>[Clinical documents, Direct Connect, Amazon S3...</td>\n",
       "      <td>[On-Premises - Clinical Documents, AWS - Direc...</td>\n",
       "      <td>[Clinical documents, Direct Connect, Amazon S3...</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aws_3.png</td>\n",
       "      <td>[Migration automation Server, Amazon Cloudfron...</td>\n",
       "      <td>[On-Premises Migration Automation Server, Amaz...</td>\n",
       "      <td>[Migration automation Server, Amazon Cloudfron...</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>azure_1.png</td>\n",
       "      <td>[Users, Client Devices , Azure Function, Azure...</td>\n",
       "      <td>[Azure Function (Collect device telemetry), Az...</td>\n",
       "      <td>[Users, Client Devices , Azure Function, Azure...</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>azure_2.png</td>\n",
       "      <td>[HTTP Traffic, Ingestion Service, Azure servic...</td>\n",
       "      <td>[HTTP Ingress (entrada de tr√°fego HTTP), Azure...</td>\n",
       "      <td>[HTTP Traffic, Ingestion Service, Azure servic...</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>azure_3.png</td>\n",
       "      <td>[Customer, Browser, Azure CDN, Blob Storage, V...</td>\n",
       "      <td>[Azure Blob Storage, Azure CDN, Azure Applicat...</td>\n",
       "      <td>[Customer, Browser, Azure CDN, Blob Storage, V...</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imagem                              componentes_esperados  \\\n",
       "0    aws_1.png  [Usuarios, AWS WAF, AWS CloudFront, AWS S3, AW...   \n",
       "1    aws_2.png  [Clinical documents, Direct Connect, Amazon S3...   \n",
       "2    aws_3.png  [Migration automation Server, Amazon Cloudfron...   \n",
       "3  azure_1.png  [Users, Client Devices , Azure Function, Azure...   \n",
       "4  azure_2.png  [HTTP Traffic, Ingestion Service, Azure servic...   \n",
       "5  azure_3.png  [Customer, Browser, Azure CDN, Blob Storage, V...   \n",
       "\n",
       "                              componentes_detectados  \\\n",
       "0  [AWS - WAF, AWS - CloudFront, AWS - API Gatewa...   \n",
       "1  [On-Premises - Clinical Documents, AWS - Direc...   \n",
       "2  [On-Premises Migration Automation Server, Amaz...   \n",
       "3  [Azure Function (Collect device telemetry), Az...   \n",
       "4  [HTTP Ingress (entrada de tr√°fego HTTP), Azure...   \n",
       "5  [Azure Blob Storage, Azure CDN, Azure Applicat...   \n",
       "\n",
       "                                componentes_corretos  f1_medio  \n",
       "0  [Usuarios, AWS WAF, AWS CloudFront, AWS S3, AW...     0.811  \n",
       "1  [Clinical documents, Direct Connect, Amazon S3...     0.806  \n",
       "2  [Migration automation Server, Amazon Cloudfron...     0.813  \n",
       "3  [Users, Client Devices , Azure Function, Azure...     0.830  \n",
       "4  [HTTP Traffic, Ingestion Service, Azure servic...     0.812  \n",
       "5  [Customer, Browser, Azure CDN, Blob Storage, V...     0.800  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä An√°lise dos Resultados\n",
    "\n",
    "A avalia√ß√£o foi conduzida sobre seis diagramas distintos ‚Äî tr√™s representando arquiteturas baseadas em servi√ßos da AWS e tr√™s em servi√ßos da Azure. Para cada imagem, foi fornecida uma lista de componentes esperados, constru√≠da manualmente com base no conte√∫do visual presente nos diagramas.\n",
    "\n",
    "### Desempenho geral\n",
    "\n",
    "Os resultados mostram que o modelo alcan√ßou **F1 Scores m√©dios entre 0.80 e 0.83** em todos os casos, com destaque para:\n",
    "\n",
    "- **`azure_1.png`** com **F1 de 0.83**, demonstrando √≥tima correspond√™ncia mesmo com nomes gen√©ricos como `\"Users\"` e `\"Client Devices\"`.\n",
    "- **Consist√™ncia entre todas as imagens**, com uma varia√ß√£o de F1 muito pequena (apenas 0.03 entre o maior e o menor valor).\n",
    "\n",
    "### Observa√ß√µes importantes\n",
    "\n",
    "- O modelo demonstrou forte **capacidade de generaliza√ß√£o sem√¢ntica**, conseguindo mapear corretamente varia√ß√µes como:\n",
    "  - `\"AWS - Lambda (Gerador de Permiss√µes)\"` ‚Üí `\"AWS Lambda\"`\n",
    "  - `\"Amazon S3 (Frontend Code)\"` ‚Üí `\"Amazon S3\"`\n",
    "  - `\"Azure Cosmos DB for MongoDB API\"` ‚Üí `\"Azure Cosmos for MongoDB API\"`\n",
    "\n",
    "- Apesar das varia√ß√µes na forma textual, **todos os componentes esperados foram corretamente identificados** em todos os casos, segundo o crit√©rio de similaridade contextual fornecido pelo BERTScore.\n",
    "\n",
    "- **Componentes compostos** e **descri√ß√µes longas** n√£o comprometeram a avalia√ß√£o: o modelo obteve boas pontua√ß√µes mesmo em casos como `\"AWS Lambda (Login Functions)\"` e `\"Azure Web App - Content Website\"`, o que refor√ßa sua capacidade de compreender a fun√ß√£o sem√¢ntica dos termos.\n",
    "\n",
    "### Ponto de destaque\n",
    "\n",
    "- A arquitetura **`aws_3.png`**, com 13 componentes esperados, foi corretamente reconhecida com F1 de **0.813**, evidenciando a escalabilidade da abordagem mesmo em diagramas mais densos e complexos.\n",
    "\n",
    "### Considera√ß√µes finais\n",
    "\n",
    "Apesar do uso exclusivo do BERTScore ‚Äî que √© mais sens√≠vel a contexto do que m√©todos com embeddings fixos ‚Äî, o modelo foi capaz de capturar corretamente os conceitos principais das arquiteturas analisadas. A abordagem se mostrou adequada para casos em que se deseja avaliar n√£o apenas igualdade textual, mas tamb√©m compreens√£o conceitual dos elementos presentes em uma imagem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Conclus√£o\n",
    "\n",
    "Esta avalia√ß√£o analisou a capacidade de um modelo de linguagem em identificar componentes arquiteturais a partir de diagramas em imagens, utilizando como m√©trica o **BERTScore**. Foram comparadas listas de componentes esperados (extra√≠das manualmente das imagens) com os componentes retornados pelo modelo, considerando similaridade sem√¢ntica e n√£o apenas igualdade literal.\n",
    "\n",
    "O **BERTScore** calcula a similaridade entre pares de palavras com base em embeddings contextuais do modelo BERT, permitindo capturar correspond√™ncias mesmo com varia√ß√µes na forma de escrita, nomes compostos ou descri√ß√µes estendidas. Isso se mostrou particularmente √∫til para componentes como `\"AWS Lambda (Validador de Permiss√µes)\"` e `\"AWS Lambda\"`, que receberam alta pontua√ß√£o mesmo com diferen√ßas textuais.\n",
    "\n",
    "Os resultados demonstraram alta precis√£o sem√¢ntica: em todas as imagens analisadas, o F1 m√©dio permaneceu **acima de 0,80**, indicando que o modelo foi capaz de identificar corretamente a grande maioria dos elementos esperados nas arquiteturas.\n",
    "\n",
    "Comparado a m√©todos que usam apenas embeddings fixos com similaridade de cosseno (como `sentence-transformers`), o uso do BERTScore tende a ser mais rigoroso e contextual, oferecendo avalia√ß√µes mais precisas em casos de ambiguidade ou descri√ß√µes mais longas ‚Äî embora com maior custo computacional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
